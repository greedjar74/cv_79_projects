{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 숫자 멀티 라벨 분류기 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV 파일 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('/Users/kimhongseok/cv_79_projects/part1/chapter3/2/data/annotations.csv')\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['filepath'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data_df.iloc[4,2]\n",
    "tmp = tmp.replace('[', '')\n",
    "tmp = tmp.replace(']', '')\n",
    "tmp = tmp.split(',')\n",
    "tmp = [int(x) for x in tmp]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, classes, data_df, transforms):\n",
    "        super().__init__()\n",
    "        self.data = []\n",
    "        self.transforms = transforms\n",
    "        self.classes = classes\n",
    "\n",
    "        data_num = data_df.shape[0]\n",
    "        img_list = data_df['filepath'].tolist()\n",
    "        cls_list = data_df['classes'].tolist()\n",
    "        \n",
    "        for i in range(data_num):\n",
    "            img = os.path.join(root_dir, img_list[i])\n",
    "            cls = cls_list[i]\n",
    "            cls = cls.replace('[', '')\n",
    "            cls = cls.replace(']', '')\n",
    "            cls = cls.split(',')\n",
    "            cls = [int(x) for x in cls]\n",
    "\n",
    "            self.data.append((img, cls))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.data[idx][0]).convert('RGB')\n",
    "        img = self.transforms(img)\n",
    "        cls = self.data[idx][1]\n",
    "        cls = torch.nn.functional.one_hot(torch.tensor(cls), len(self.classes)).sum(dim=0).to(torch.float) # sum을 안 하면 각각에 대해서 one-hot이 되어있다. sum을 통해 하나의 리스트로 만들어준다.\n",
    "        \n",
    "        return img, cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = T.Compose([\n",
    "    T.Resize((112, 224)),\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "total_dataset = CustomDataset('/Users/kimhongseok/cv_79_projects/part1/chapter3/2/data', classes, data_df, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(total_dataset[0][0].permute(1, 2, 0))\n",
    "plt.title(total_dataset[0][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num = len(total_dataset)\n",
    "train_num, valid_num, test_num = int(total_num*0.8), int(total_num*0.1), int(total_num*0.1)\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(total_dataset, [train_num, valid_num, test_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=20, shuffle=False)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=20, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_dataloader, train_dataset, criterion, optimizer, threshold, epoch, num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "\n",
    "    tbar = tqdm(train_dataloader)\n",
    "    for images, labels in tbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = (torch.sigmoid(outputs) > threshold).float()\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        total_labels.extend(labels.cpu().numpy())\n",
    "        total_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        tbar.set_description(f'Epoch/Epochs [{epoch+1}/{num_epochs}]')\n",
    "\n",
    "    train_loss = train_loss / len(train_dataloader)\n",
    "    train_f1 = f1_score(total_labels, total_preds, average='micro')\n",
    "\n",
    "    return model, train_loss, train_f1\n",
    "\n",
    "def evalutation(model, valid_dataloader, valid_dataset, criterion, threshold, epoch, num_epochs):\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    total_labels = []\n",
    "    total_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        tbar = tqdm(valid_dataloader)\n",
    "        for images, labels in tbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            preds = (torch.sigmoid(outputs) > threshold).float()\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "            total_labels.extend(labels.cpu().numpy())\n",
    "            total_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "            tbar.set_description(f'Epoch/Epochs [{epoch+1}/{num_epochs}]')\n",
    "\n",
    "    valid_loss = valid_loss / len(valid_dataloader)\n",
    "    valid_f1 = f1_score(total_labels, total_preds, average='micro')\n",
    "\n",
    "    return model, valid_loss, valid_f1\n",
    "\n",
    "def training_loop(model, train_dataloader, train_dataset, valid_dataloader, valid_dataset, criterion, optimizer, threshold, num_epochs):\n",
    "    model.to(device)\n",
    "    train_loss_list = []\n",
    "    train_f1_list = []\n",
    "    valid_loss_list = []\n",
    "    valid_f1_list = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model, train_loss, train_f1 = training(model, train_dataloader, train_dataset, criterion, optimizer, threshold, epoch, num_epochs)\n",
    "        model, valid_loss, valid_f1 = evalutation(model, valid_dataloader, valid_dataset, criterion, threshold, epoch, num_epochs)\n",
    "\n",
    "        train_loss_list.append(train_loss)\n",
    "        train_f1_list.append(train_f1)\n",
    "        valid_loss_list.append(valid_loss)\n",
    "        valid_f1_list.append(valid_f1)\n",
    "\n",
    "        print(f'Train Loss: {train_loss}, Train F1: {train_f1}, Valid Loss: {valid_loss}, Valid F1: {valid_f1}')\n",
    "\n",
    "    return model, train_loss_list, train_f1_list, valid_loss_list, valid_f1_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = torch.nn.Linear(2048, 10)\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model, train_loss_list, train_f1_list, valid_loss_list, valid_f1_list = training_loop(model, train_dataloader, train_dataset, valid_dataloader, valid_dataset, criterion, optimizer, 0.5, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total_preds = []\n",
    "total_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    tbar = tqdm(test_dataloader)\n",
    "    for images, labels in tbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = (torch.sigmoid(outputs) > 0.5).int()\n",
    "\n",
    "        total_labels.extend(labels.cpu().numpy())\n",
    "        total_preds.extend(preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(total_preds, total_labels, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for i in range(20):\n",
    "    ax = plt.subplot(4, 5, i+1)\n",
    "    img = plt.imshow(test_dataset[i][0].permute(1, 2, 0))\n",
    "    real = []\n",
    "    preds = []\n",
    "\n",
    "    for j in range(10):\n",
    "        if total_labels[i][j] == 1:\n",
    "            real.append(j)\n",
    "\n",
    "        if total_preds[i][j] == 1:\n",
    "            preds.append(j)\n",
    "\n",
    "    plt.title(f'True: {real}\\nPred: {preds}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
